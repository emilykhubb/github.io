%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Short Sectioned Assignment
% LaTeX Template
% Version 1.0 (5/5/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Frits Wenneker (http://www.howtotex.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[paper=a4, fontsize=11pt]{scrartcl} % A4 paper and 11pt font size

\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{float}
\usepackage{graphicx}
\usepackage{listings}
    \lstset{language=R}
\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
\usepackage{fourier} % Use the Adobe Utopia font for the document - comment this line to return to the LaTeX default
\usepackage[english]{babel} % English language/hyphenation
\usepackage{amsmath,amsfonts,amsthm,amssymb} % Math packages
\usepackage{graphicx}
\usepackage{url}

\usepackage{lipsum} % Used for inserting dummy 'Lorem ipsum' text into the template

\usepackage{sectsty} % Allows customizing section commands
\allsectionsfont{\centering \normalfont\scshape} % Make all sections centered, the default font and small caps

\usepackage{fancyhdr} % Custom headers and footers
\pagestyle{fancyplain} % Makes all pages in the document conform to the custom headers and footers
\fancyhead{} % No page header - if you want one, create it in the same way as the footers below
\fancyfoot[L]{} % Empty left footer
\fancyfoot[C]{} % Empty center footer
\fancyfoot[R]{\thepage} % Page numbering for right footer
\renewcommand{\headrulewidth}{0pt} % Remove header underlines
\renewcommand{\footrulewidth}{0pt} % Remove footer underlines
\setlength{\headheight}{13.6pt} % Customize the height of the header
\numberwithin{equation}{section} % Number equations within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{figure}{section} % Number figures within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{table}{section} % Number tables within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)

\setlength\parindent{0pt} % Removes all indentation from paragraphs - comment this line for an assignment with lots of text

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\newcommand{\horrule}[1]{\rule{\linewidth}{#1}} % Create horizontal rule command with 1 argument of height
\newcommand{\argmax}{\arg\!\max}
\title{	
\normalfont \normalsize 
\textsc{Mississippi State University} \\ [25pt] % Your university, school and/or department name(s)
\horrule{0.5pt} \\[0.4cm] % Thin top horizontal rule
\huge Data Analysis One  \\ % The assignment title
\horrule{2pt} \\[0.5cm] % Thick bottom horizontal rule
}

\author{Emily Hubbard} % Your name

\date{\normalsize\today} % Today's date or a custom date

\begin{document}

\maketitle % Print the title

%----------------------------------------------------------------------------------------
%	PROBLEM 1
%----------------------------------------------------------------------------------------

\section*{HW 1}
%\lipsum[2] % Dummy text

\textbf{SECTION ONE}\\

\textbf{Executive Summary:}\\

\textbf{A. Introduction:} \\
It is important to understand the factors and influences that go into the survival time of leukemia patients. Questions such as: Does a certain amount of sleep increase length of life? Does going through chemotherapy during a certain timezone of illness positively impact survival time? Does white blood count indicate how long a patient will live? These questions are crucial in understanding the illness and being able to accurately predict the lifespan of someone with leukemia. Those are the kinds of questions we will address in this report. Specifically, we will be assessing whether or not white blood count(wbc) or presenc of antigens(ag) indicates longer or shorter survival times in leukemia patients. We will use logistic linear regression to create a model that best predicts whether or not a person will survive for 24 weeks or more given certain values of wbc and ag. We want to know if these two variables, wbc and ag, have a meaningful relationship with survival time under a logistic model.\\ 

A logistic linear model is based on the following formula:
\begin{align}
\nonumber
&\text{log}\left(\frac{p(X)}{1-p(X)}\right) = \alpha + \beta_iX_i + \epsilon\\
&\text{where } \text{log}\left(\frac{p(X)}{1-p(X)}\right) \text{ is the log-odds or logit. }
\nonumber
\end{align} \\

Using R to create a logistic linear regression model will give us coefficients for each of the covariates. These coefficients gives us the "log-odds" of the effect that covariate has on the response. For example, if the coefficient were 4.35, then we could say that, holding other variables constant, a 1-unit increase in that covariate multiplies the odds of being in category 1 by $e^{4.35}$.\\

\textbf{B. Data Collection}\\

\begin{figure}[H]
    \centering
    \includegraphics[width=0.52\linewidth]{Data Table.png}
    \caption{Leuk Data}
    \label{fig:enter-label}
\end{figure}

The data in Figure 0.1, Table 7.6 shows the survival times of patients diagnosed with leukemia and the values of two explanatory variables, the white blood cell count (wbc) and the presence or absence of antigens within the white blood cells (ag).\\

The following portion of R code describes the variable types of the original data variables as well as log transformed or factored variables that were added to aid in model creation.\\

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\linewidth]{Variable Types.png}
    \caption{Leuk Data Variable Types}
    \label{fig:enter-label}
\end{figure}

\begin{itemize}
\item \textbf{"wbc"} represents the white blood cell count for each of the 33 leukemia patients. It is a quantitative, continuous variable.
\item \textbf{"ag"} represents the presence or absence of certain antigens in the cells. This variable is qualitative, categorical, and has two levels (“present” and “absent”).
\item \textbf{"time"} represents the survival time in weeks of each patient. This variable is quantitative and continuous.
\item \textbf{"time.binary"} represents the variable time transformed into a binary outcome where 0 means the patient survived less than 24 weeks and 1 means the patient survived at least 24 weeks. This is a binary, quantitative variable.
\item \textbf{"time.binary.factor"} represents the same binary outcome recoded as a factor variable with two levels (“$>$ 24 weeks” and “$\leq$ 24 weeks”). To build a logistic regression model, the response variable must be categorical, aka have different factor levels. This redefined variable allows for R to run a logistic regression model on the data. This variable is binary and categorical.
\item \textbf{"wbc.log"} represents the log transformation of the wbc variable. This will be utilized to create the most efficient model to predict survival time because it helps reduce the effect of extreme outliers. Just like wbc, it remains a quantitative, continuous variable.
\end{itemize}

To be clear, the response variable will be "time" (in factor form) and the covariates will be "wbc" (log transformed to reduce skew) and "ag". \\

\textbf{C. Summary Information}\\ 
\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\linewidth]{1.1 Summary of Original Data.png}
    \caption{Basic Summary of Leuk Data}
    \label{fig:enter-label}
\end{figure}

Given this summary of the data, there are a few observations we can make:
\begin{enumerate}
\item There is a significant difference in the mean and median of both wbc and time. This indicates that wbc and time columns contain outliers. Some transformations will need to be made on the data to create a more stable and reliable logistic model.
\item The presence of antigens is almost evenly split among the observed patients.
\item "Time" is currently a numerical value and to run a logistic model, we need a categorical response variable. We will fix this issue by transforming time into a binary outcome variable and assigning it to two factor levels, “$<$ 24 weeks” and “$\geq$ 24 weeks”.
\end{enumerate}

\medskip

Let's take a closer look at the response variable and associated covariates with some visuals.\\

\textbf{Response Variable: "Time"}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\linewidth]{1.Histogram Survival Time (in weeks).pdf}
    \caption{Histogram of Survival Time (in weeks)}
    \label{fig:enter-label}
\end{figure}
\textbf{Observations:}
It looks as though from this chart, the more freguent outcome of patients is that they live less than 24 weeks. There is also a very wide spread of survival times and it is right skewed. Categorizing them into $<$ 24 weeks or  $\geq$ 24 weeks will remove the effect of the outliers because magnitude of the value will not be taken into account.\\

\textbf{Covariate 1: White Blood Count (wbc)} 
\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\linewidth]{2. Histogram of White Blood Count (wbc).pdf}
    \caption{Histogram of White Blood Count (wbc)}
    \label{fig:enter-label}
\end{figure}
\textbf{Observations:}
This figure allows us to visualize outliers within the white blood count observations. The effect of these outliers will be greatly reduced when we take the log transformation and use that in its place when creating the model. \\

\textbf{Covariate 2: Antigen Presence (ag)}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{3. Antigen Presence.pdf}
    \caption{Antigen Presence (ag)}
    \label{fig:enter-label}
\end{figure}
\textbf{Observations:}
Just as we observed in the summary output from R, figure 0.6 also shows that the presence of antigens is almost evenly split among the observed patients.\\

Now, we will look at each covariate individually and assess its effect on the response variable.\\

\textbf{Visualization of "ag" and "time" together:}\\ 
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{4. Visualization of AG and Survival Time.pdf}
    \caption{ag and Survival Time}
    \label{fig:enter-label}
\end{figure}
\textbf{Observations:}
This group bar chart indicates a possible relationship with these two variables. It seems that shorter survival times are more likely to occur when ag is absent.\\

\textbf{Visualization of "wbc" and "time" together:}\\ 
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{5. wbc by Survival Outcome.pdf}
    \caption{wbc and Survival Time}
    \label{fig:enter-label}
\end{figure}
\textbf{Observations:}
This box-plot visual tells us a little bit about the relationship between survival time and wbc. It seems as though a lower wbc is more common in those who survived more than 24 weeks. Conversely, a higher wbc seems to be more likely in shorter survival times. This is noticed by looking at the medians (black bars) and noticing their positions in relation to the y-axis.\\

\textbf{Overall Observations Given the Summary Data and Visuals:}
After looking at the response variable and each covariate individually, I wonder if there will be a good logistic regression model to predict the response because there does seem to be a positive association between lower wbc and survival times as well as a positive association between ag presence and survival time. \\

The question remains: Can we explain the relationship between wbc and ag on time with a logistic regression model? Let's find out.




\begin{enumerate}
    \item First, we will define a binary outcome variable according to whether or not patients lived for at least 24 weeks after diagnosis. \\

\[
Y = 
\begin{cases}
0 & \text{if < 24 weeks}\\
1 & \text{if $\geq$ 24 weeks}\\
\end{cases}
\]\\

The response variable Y, survival time, will be split into two categories that will be sorted into 1 or 0. The logistic regression model will help us predict the likelihood of the response variable falling into category 1, which in this case is $\geq$ 24 weeks. 


    \item Now, we will fit a logistic regression model to the data. \\

\textbf{Summary of the Model:}\\ 
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{6. R Summary of Model One .png}
    \caption{R Summary Output}
    \label{fig:enter-label}
\end{figure}   

\textbf{Regression Line Equation:}
\begin{align}
\nonumber
&\text{Intercept}(\alpha) =3.456\\
\nonumber
&\text{Coefficient 1}(\beta_1) = -0.482 \\
\nonumber
&\text{Coefficient 2}(\beta_2) = 1.762 \\
\nonumber
&\text{log}\left(\frac{p(X)}{1-p(X)}\right) = 3.456 -0.482(\text{log.wbc}) +1.762(\text{ag}) + \epsilon\\
\nonumber
\end{align}  


\textbf{Summary Statistics:}
\begin{align}
\nonumber
&\frac{\text{Residual Deviance}}{\text{DF}} = \frac{37.498}{30}=1.25\\
\nonumber
&\text{AIC} = 43.498\\
\nonumber
\end{align}  

\textbf{Interpretation of the Summary:}\\
The presence of antigens are shown to have a significant impact on the response variable survival time. This is indicated by the p-value being less than a standard 5 percent $\alpha$(0.03). People with the presence of antigens have a 5.8 times higher chance of surviving at least 24 weeks. This is calculated by taking e and raising it to the coefficient corresponding to AG. $e^1.76$ = 5.8. This logistic regression model suggests that white blood count does not have a significant impact on survival time. This is also shown by the p-value being much greater than 5 percent(0.13). To check whether or not this model is overfit, we divide the residual deviance by the degrees of freedom. In this case, we get 1.25 as stated above which is below the threshold of 1.5, indicating this model is not overfit. This is good. This means that our data, if significant, can be applied to other data sets and at least somewhat help in predicting the response variable outcome. \\

    \item Finally, we will construct some graphics useful in the interpretation of the fitted model. \\

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\linewidth]{Visualization of Model for Time, wbc, and ag.pdf}
    \caption{Predicted Probabilities of Survival time $\geq$ 24 weeks}
    \label{fig:enter-label}
\end{figure}

\textbf{Explanation:}\\ 
This plot shows us the probabilities of the response variable falling into category 1 ($\geq$ 24 weeks) given antigen presence and white blood count. The blue line represents patients with antigens present in their white blood cells. These people overall have a greater chance of surviving at least 24 weeks, compared to their absent antigen counterparts. It is also important to note that when antigens are present or absent, survival times decrease as the white blood count increases. So, best case scenario for survival is to have a lower white blood count with antigens present. \\



\textbf{SECTION TWO}\\

\textbf{Executive Summary:}\\

\textbf{A. Introduction:} \\
The stock market is an important part of the modern financial landscape. It is also a way to make a lot of money. Many people would kill to know just what the stock market will do on any given day, so many a statistical model has been built in an attempt to predict the direction and magnitude in which the stock market will change. We will attempt to predict the direction  of the market in a given week with the information of 9 covariates and a logistic regression model. Will we be able to fit a model that can make meaningful predictions about the stock market?\\ 

As previously stated, a logistic linear model is based on the following formula:
\begin{align}
\nonumber
&\text{log}\left(\frac{p(X)}{1-p(X)}\right) = \alpha + \beta_iX_i + \epsilon\\
&\text{where } \text{log}\left(\frac{p(X)}{1-p(X)}\right) \text{ is the log-odds or logit. }
\nonumber
\end{align} \\

\textbf{B. Data}\\

The data that we are working with is from the ISLR R package and consists of the weekly percentage returns for the S and P 500 stock index between 1990 and 2010.\\

The following portion of R code describes the variable types of the original data variables.\\

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\linewidth]{Variable Types Section Two.png}
    \caption{Weekly Data Variable Types}
    \label{fig:enter-label}
\end{figure}

\begin{itemize}
\item \textbf{"Year"} The year that the observation was recorded. This is a discrrete variable.
\item \textbf{"Lag1 - Lag5"} Percentage return for n weeks previous (n= 1,2,3,4,5). Each Lag is a continuous, quantitative variable.
\item \textbf{"Volume"} Volume of shares traded (average number of daily shares traded in billions). This is a continuous, quantitative variable.
\item \textbf{"Today"} Percentage return for this week. This is also a continuous, quantitative variable.
\item \textbf{"Direction"} levels Down and Up indicating whether the market had a positive or negative return on a given week. This variable is a two-level factor with binary outcome 0 referring to "Down" and 1 meaning "Up".
\end{itemize}

To be clear, the response variable will be "direction" and the covariates will be "Lag 1 - Lag5" (log transformed to reduce skew) and "Volume". We are not going to include the "Year" or the "Today" column in our model.\\

\textbf{C. Summary Information}\\ 

\textbf{Numerical Summary}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\linewidth]{Screenshot 2025-09-30 at 9.43.44 PM.png}
    \caption{Basic Summary of Weekly Data}
    \label{fig:enter-label}
\end{figure}

Given this summary of the data, there are a few observations we can make:
\begin{enumerate}
\item The medians and means of all of the Lag variables have similar values of difference. Each of them having around a 0.10 difference between median and mean. 
\item There are more "Up" observations than "Down".
\item There will be no need to transform any existing variables because they are already in perfect form to run a logistic regression model.\\
\end{enumerate}

\textbf{Graphical Summary}

\begin{figure}[H]
  \centering
  \begin{minipage}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{7. Correlation Chart (Weekly Data Set).pdf}
    \caption{Correlation Chart (Weekly Data Set)}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{8. Spearman Correlation Chart (Weekly Data Set)).pdf}
    \caption{Spearman Correlation Chart (Weekly Data Set)}
  \end{minipage}
\end{figure} 

\textbf{Interpretation:}\\ 
Looking at both the normal correlation chart (Figure 0.13) as well as the spearman correlation chart (Figure 0.14), there seems to be very little, if any, correlation between lags. There are some significant correlation values shown the spearman chart, however, they are so small that with such a large data set, it does not make a meaningful difference. Based on the first correlation chart, we can see a positive exponential relationship between time and volume, which makes sense. Since the development of the stock market, increasingly more people use it and the network affect occurs. As more people use it, it becomes a better market tool, meaning even more people want to participate. This is an easy explanation for the pattern.\\

Now, we will create our logistic regression model to answer the question: Will we be able to fit a model that can make meaningful predictions about the stock market?

\begin{enumerate}
    \item We will use the full data set to perform a logistic regression with Direction as the response and the five lag variables plus Volume as predictors. Then we wil use the summary function to print the results. We will then discuss if any of the predictors appear to be statistically significant and if so, which ones.\\

\[
Y = 
\begin{cases}
0 & \text{if Down}\\
1 & \text{if Up}\\
\end{cases}
\]\\


\textbf{Summary of the Model:}\\ 
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{10. Summary of Model 3 Weekly Data Set.png}
    \caption{R Summary Output}
    \label{fig:enter-label}
\end{figure}   

\textbf{Regression Line Equation:}
\begin{align}
\nonumber
&\text{Intercept}(\alpha) = 0.267\\
\nonumber
&\text{Coefficient 1}(\beta_1) = -0.041 \\
\nonumber
&\text{Coefficient 2}(\beta_2) = 0.058 \\
\nonumber
&\text{Coefficient 3}(\beta_3) = -0.016 \\
\nonumber
&\text{Coefficient 4}(\beta_4) = -0.028 \\
\nonumber
&\text{Coefficient 5}(\beta_5) = -0.014 \\
\nonumber
&\text{Coefficient 6}(\beta_6) = -0.023 \\
\nonumber
&\text{log}\left(\frac{p(X)}{1-p(X)}\right) = 0.267 -0.041(\text{Lag1}) +0.058(\text{Lag2})-0.016(\text{Lag3})\\
\nonumber
&-0.028(\text{Lag4}) -0.014(\text{Lag5})
-0.023(\text{Volume})+ \epsilon\\
\nonumber
\end{align}  


\textbf{Summary Statistics:}
\begin{align}
\nonumber
&\frac{\text{Residual Deviance}}{\text{DF}} = \frac{1496}{1082}=1.38\\
\nonumber
&\text{AIC} = 1500\\
\nonumber
\end{align}  

\textbf{Interpretation of the Summary:}\\
Using the summary function in R, it can be seen that only one covariate is calculated to be significant. Based on its p-value less than 0.05, Lag 2 is significant in predicting the response variable direction. No other covariate has a significant p-value. When dividing Residual deviance by degrees of freedom to check the fit of the model, the result indicates it is close to being overfit. Greater than 1.5 means a model is overfit and this model is 1.38. It also has a 1500 AIC score. This will become more meaningful in comparison to another model.\\

    \item We will now compute the confusion matrix and explain what it is telling us about the mistakes made by logistic regression. We will then calculate what the misclassification rate is. This number will tell us the percentage of times the model makes the wrong prediction about the response variable's category.\\

\textbf{Confusion Matrix:}\\ 
\begin{figure}[H]
    \centering
    \includegraphics[width=0.30\linewidth]{11. Confusion Matrix for Full Model.png}
    \caption{Confusion Matrix for Full Model}
    \label{fig:enter-label}
\end{figure}

\textbf{Misclassification Rate:} 0.4389 or 43.89 percent\\ 

\textbf{Interpretation:}\\ 
This misclassification stat tells us that 44 percent of the time, this model will predict the wrong category for the response variable to go in. This is supported by the confusion matrix. 430 observations were misclassified as "Up" when in reality they were "Down". Another 48 observations were categorized as "Down" when they were actually "Up". This indicates just how faulty this model is. It is not surprising since only one covariate was calculated to be significant.

   \item Now, what if we were to use only Lag 2 (the significant covariate) in a logistic regression model to predict Direction. Would that help in increasing the accuracy of the model? That is what we will see. In this next model, we will also use a training set and a test set so that we can more officially test if this model gives us the right predictions.\\

\textbf{Summary of the Model (Only Lag2):}\\ 
\begin{figure}[H]
    \centering
    \includegraphics[width=0.80\linewidth]{Screenshot 2025-09-30 at 10.45.29 PM.png}
    \caption{R Summary Output}
    \label{fig:enter-label}
\end{figure} 

\textbf{Regression Line Equation:}
\begin{align}
\nonumber
&\text{Intercept}(\alpha) =0.203\\
\nonumber
&\text{Coefficient 1}(\beta_1) = 0.058\\
\nonumber
&\text{log}\left(\frac{p(X)}{1-p(X)}\right) =  0.203 +0.058(\text{Lag2}) + \epsilon\\
\nonumber
\end{align} 

\textbf{Summary Statistics:}
\begin{align}
\nonumber
&\frac{\text{Residual Deviance}}{\text{DF}} = \frac{1350.5}{983}=1.37\\
\nonumber
&\text{AIC} = 1354.5\\
\nonumber
\end{align}  

\textbf{Interpretation of the Summary:}\\
This model has a slightly lower AIC score, but that is the only number in this summary output that can give us any indication of how it compares to the other test. A confusion matrix for this model followed by a misclassification rate can more clearly indicate which model is superior if any. 

\textbf{Confusion Matrix:}\\ 
\begin{figure}[H]
    \centering
    \includegraphics[width=0.30\linewidth]{10.5 Confusion Matrix for Lag2 Only Model.png}
    \caption{Confusion Matrix for Lag2 Only Model}
    \label{fig:enter-label}
\end{figure}

\textbf{Misclassification Rate:} 0.4375 or 43.75 percent\\ 

\textbf{Interpretation:}\\ 
Compared to the full model, this model that only takes into account Lag 2 has about the same amount of predictive power. This can be supported by a few things. The misclassification rate is a mere 0.0012 lower than with the full model. There were 476 misclassified observations out of 1088. The only other thing that points to this model being superior is the slight decrease in the AIC score from 1500 (full model) to 1354 (current model). However, this model still does not do a great job of predicting the likelihood of the response variable falling into the "Up" Direction category.


\item We are now going to repeat this process using the Linear Discriminant Analysis Model (LDA) and eventually compare which if either of the models are superior.\\

\textbf{Confusion Matrix:}\\ 
\begin{figure}[H]
    \centering
    \includegraphics[width=0.30\linewidth]{13. Confusion Matrix for LDA Model.png}
    \caption{Confusion Matrix for LDA Model}
    \label{fig:enter-label}
\end{figure}

\textbf{Misclassification Rate:} 0.4384 or 43.84 percent\\ 

\textbf{Interpretation:}\\ 

\item We are now going to repeat this process using the Quadratic Discriminant Analysis Model (QDA) and compare if this model is better than any of the previous ones.\\

\textbf{Confusion Matrix:}\\ 
\begin{figure}[H]
    \centering
    \includegraphics[width=0.30\linewidth]{14. Confustion Matrix for QDA.png}
    \caption{Confustion Matrix for QDA Model}
    \label{fig:enter-label}
\end{figure}

\textbf{Misclassification Rate:} 0.4439 or 44.39 percent\\ 

\textbf{Interpretation:}\\ 
This QDA model does not increase the accuracy. In fact, it decreases it by a small amount. This again points to Lag2 not having enough significane for the test to differentiate the correct category for the response variable. Especially for this test. It predicted only "Up" classifications. \\

\item Considering each of these three models, which of these methods appears to provide the best results on this data?\\

All three of these models, Logistic, LDA, and QDA, come out with very similar predictions and misclassifications rates. All of them being approximately 56 percent accurate and 44 percent wrong. This is barely better than flipping a coin to choose a category. There confusion matrices, though slightly different, hold pretty much the same amount of misclassified information. The Logistic Regression Model is the best of the 3 based on smallest misclassification rate though the difference is practically negligible. Overall, I would say that this model, nor any of the others in this report, can accurately predict the response variable direction. 


\end{enumerate}

\newpage

\textbf{\underline{APPENDIX}}\\
\textbf{R code:}\\

    \begin{lstlisting}[language=R]
  #### HW 3 ####
#### Section One ####
library(MASS)

##Visualization and Understanding of Original Data:
?leuk
data("leuk")  
View(leuk)
names(leuk)
# Y: "time" (in weeks) X's: "wbc" (white blood count) "ag" (antigen presence or absence)

dim(leuk)
# 3x33

str(leuk)

summary(leuk)
#looking at "time", it is noticeable how big a difference there is between the median and 
#the mean. The median, 22, is a better representation of this data set of 33 people because
#the max observation skews the rest of the sample.

##Visualization of Response Variable "Time":
hist(leuk$time,xlab = "Survival Time (in weeks)", main = "Histogram Survival Time (in weeks)",xaxt = "n", yaxt = "n")
axis(1, at = seq(0, 160, by = 20))
axis(2, at = seq(0, 16, by = 4))

##Visualization of Response Variable "wbc":
hist(leuk$wbc,xlab = "White Blood Count (wbc)", main = "Histogram of White Blood Count (wbc)", yaxt = "n", breaks = 10)
axis(2, at = seq(0, 20, by = 4))

##Visualization of Response Variable "ag":
str(leuk$ag)
table(leuk$ag)
contrasts(leuk$ag)

barplot(table(leuk$ag),main = "Presence vs Absence of AG (Antigen)", xlab = "AG",ylab = "Frequency",)
#What I notice from this barplot is that it is pretty 50/50 on whether or not the antigens will be present or absent.

##Visualize "AG" and "Time" together:
library(ggplot2)

ggplot(leuk, aes(x =  ag, fill = time.binary.factor)) +
  geom_bar(position = "dodge") +
  labs(title = "Visualization of AG and Survival Time", x = "ag", y = "Frequency", fill = "Survival Time") 
#This group bar chart indicates a possible relationship with these two variables. It seems that 
#shorter survival times are more likely to occur when ag is absent.

##Visualize ""WBC" and "Time" together:
ggplot(leuk, aes(x = time.binary.factor, y = wbc, fill = time.binary.factor)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = "wbc by Survival Outcome", x = "Survival Time", y = "wbc")
#This box-plot visual tells us a little bit about the relationship between survival time and wbc.
#It seems as though a lower wbc is more common in those who survived more than 24 weeks. Conversely, a higher wbc seems to be more likely in shorter survival times.
#This is noticed by looking at the medians (black bars) and noticing their positions in relation to the y-axis.

##After looking at the response variable and each covariate individually, I wonder if there will be a good logistic regression model
#to predict the response because there does seem to be a positive association between lower wbc and survival times as well as a 
#positive association between ag presence and survival time. So maybe, it doesn't matter how many white blood cells there are as long as 
#the antigen is present withing them. So, can we explain this relationship with a logistic regression model? Let's find out.


#### 1 ####
leuk$time.binary <- ifelse(leuk$time < 24, 0, 1) #creating a binary outcome
leuk$time.binary.factor <- factor(leuk$time.binary, levels = c(0, 1), labels = c("< 24 weeks", "≥ 24 weeks")) #putting it into factor form

##Data Checking:
str(leuk$time.binary.factor) #checking that it was properly converted into a factor
table(leuk$time.binary.factor)  #counts within factor levels
contrasts(leuk$time.binary.factor) #shows us the number assigned to each level...
#In our logistic regression, we will be calculating the probability that the response variable Y is in group 1.

#### 2 ####
leuk$wbc.log <- log(leuk$wbc)  #natural log transformation for wbc
str(leuk$wbc.log)

##Visualize the log transformation of wbc
hist(leuk$wbc.log,xlab = "White Blood Count (wbc)", main = "Histogram of Log Transformation of White Blood Count (wbc)")

model.1 <- glm(time.binary ~ wbc.log + ag, data = leuk, family = binomial)
model.1

summary(model.1)
exp(model.1$coefficients) #This indicates what odds a patient has of surviving at least 24 weeks given they have antigens present.
#Logistic Equation: logit = 3.4556 - 0.4822(log.wbc) + 1.7621 (leuk.agpresent)
#Interpretation: The presence of antigens have shown a significant impact on the response variable survival time.
#This is indicated by the p-value being less than a standard 5% alpha. People with the presence of antigens have a 5.8 times 
#higher chance of surviving at least 24 weeks. This is calculated by exponentiating the coefficient corresponding to AG. e^1.76 = 5.8. This logistic regression suggests that white 
#blood count does not have a significant impact on survival time. This is also shown by the p-value being much greater than 5%.
#To check whether or not this model is overfit, we divide the residual deviance by the degrees of freedom. In this case, we 
# get 1.25 which is below the threshhold of 1.5 which would indicate an overfit model. This is good. This means that our data, if significant, can be applied
#to other data sets and at least somewhat help in predicting the response variable outcome.



model.2 <- glm(leuk$time.binary ~ leuk$wbc + leuk$ag, family = binomial)
model.2
#Logistic Equation: logit = -8.706e-01 - 8.436e-06(wbc) + 1.733 (leuk.agpresent)
#This is a test of what the model would look like in if we did not take the natural log of wbc. The AIC is slightly higher than model 1, indicating that
#this model underperforms model 1 slightly. Model 1 is also slightly easier for interpretation purposes.


#### 3 ####
##Graphic for model interpretation: 
# 2) Build prediction grid
newdata <- with(leuk, expand.grid(
  wbc.log = seq(min(wbc.log), max(wbc.log), length.out = 200),
  ag      = levels(ag)
))

# 3) Predict from the model
newdata$predicted_prob <- predict(model.1, newdata = newdata, type = "response")

# Plot
library(ggplot2)
ggplot(newdata, aes(x = wbc.log, y = predicted_prob, color = ag)) +
  geom_line(size = 1.2) +
  labs(title = "Predicted Probability of Surviving ≥ 24 Weeks",
       x = "Log of White Blood Count (log WBC)",
       y = "Predicted Probability", color = "Antigen Presence") +
  theme_minimal(base_size = 13)



#### Section Two ####
library(ISLR)
##Visualization and Understanding of Original Data:
?Weekly
data("Weekly")  
View(Weekly)
names(Weekly)
# "Year"      "Lag1"      "Lag2"      "Lag3"      "Lag4"      "Lag5"      "Volume"    "Today"     "Direction"
dim(Weekly)
# 1089 x 9
str(Weekly)
#All are continuous except for direction, which is a factor.

summary(Weekly)

contrasts(Weekly$Direction) #Up is 1 which means the odds that we calculate will indicate the likelihood of the reponse being up in direction.

#### 1 ####
##Visualization of Original Data
par(mex=0.5)    #test for independent covariates
pairs(Weekly, gap=0, cex.labels=0.9)
cor(Weekly) 

library(PerformanceAnalytics)

chart.Correlation(Weekly[,-c(1,9)],method="spearman",histogram=TRUE,pch=16)

##Looking at both the normal correlation chart as well as the spearman correlation chart, there seems to be very little if any correlation between lags.
#There are some significant correlation values, however, they are so small that with such a large data set, it does not make a meaningful difference.
#Based on the first correlation chart, we can see an positive exponential relationship between time and volume, which makes sense. Since the developement of the 
#stock market, increasingly more people use it the net work affect occurs. As more people use it, it becomes a better market tool, meaning even more people
#want to participate. This is an easy explanation for that pattern.

#### 2 ####
model.3 <- glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, data = Weekly, family = binomial)
model.3

summary(model.3)
#Using the summary function in R, it can be seen that only one covariate is calculated to be significant.
#Based on its p-value less than 0.05, Lag 2 is significant in predicting the response variable direction. 
#No other covariate has a significant p-value. When dividing Residual deviance by degrees of freedom to check 
#the fit of the model, indicates it is close to being overfit. Greater than 1.5 means a model is overfit and this 
#model is 1.37. It also has a 1500 AIC score. This will become more meaningful in comparison to another model.

#### 3 ####
prob <- predict(model.3, type = "response")
predicted.classes <- ifelse(prob > 0.5, "Up", "Down")
conf.mat <- table(Predicted = predicted.classes, Actual = Weekly$Direction)
conf.mat

accuracy <- mean(predicted.classes == Weekly$Direction)
misclassification_rate <- 1 - accuracy
accuracy #=0.5611
misclassification_rate #=0.4389
##This misclassification stat tells us that 44 % of the time, this model will predict the wronf category for the response variable to go in.
#This is supported by the confusion matrix. 430 observations were misclassified as "Up" when in reality they were "Down". Another 48 observations 
#were categorized as "Down" when they were actually "Up". This indicates just how faulty this model is. It is not surprising since only one covariate was
#calculated to be significant.

#Now, what if we were to use only Lag 2 (the significant covariate) in a logistic regression model to predict Direction.
#Would that help in increasing the accuracy of the model? That is what we will see. In this next model, we will also use
#a training set and a test set so that we can more officially test if this model gives us the right predictions.

#### 4 ####
##Training data:
train <- (Weekly$Year < 2009)      
Weekly.train <- Weekly[train, ]    
Weekly.test <- Weekly[-train, ] 

model.4 <- glm(Direction ~ Lag2, data = Weekly.train, family = binomial)
model.4

summary(model.4)

##Predication using test data
glm.probs <- predict(model.4, newdata = Weekly.test, type = "response")
glm.pred <- rep("Down", nrow(Weekly.test))
glm.pred[glm.probs > 0.5] <- "Up"

# Confusion matrix
Direction.test <- Weekly.test$Direction
conf.mat.2 <- table(glm.pred, Direction.test)
conf.mat.2
accuracy.2 <- mean(glm.pred == Direction.test)
misclassification_rate.2 <- 1 - accuracy.2
accuracy.2 #=0.5625
misclassification_rate.2 #=0.4375
#Compared to the full model, this model that only takes into account Lag 2 has about the same amount of predictive power.
#This can be supported by a few things. The misclassification rate is a mere 0.0012 lower than with the full model. There were 476 misclassified observations out of 1088.
#The only other thing that points to this model being superior is the slight decrease in the AIC score from 1500 (full model) to 1354 (current model). 
#However, this model still does not do a good job of predicting the likelihood of the response variable ending up in the "Up" Direction category.

#### 5 ####
##LDA Model Fitting
model.4.lda <- lda(Direction ~ Lag2, data = Weekly.train)
model.4.lda

lda.pred <- predict(model.4.lda, Weekly.test)

Direction.test <- Weekly.test$Direction
conf.mat.3 <- table(lda.pred$class, Direction.test)
conf.mat.3
accuracy.lda <- mean(lda.pred$class == Direction.test)
misclassification_rate.lda <- 1 - accuracy.lda
accuracy.lda #=0.5616
misclassification_rate.lda #=0.4384

#### 6 ####
##QDA Model Fitting
model.4.qda <- qda(Direction ~ Lag2, data = Weekly.train)
model.4.qda

qda.pred <- predict(model.4.qda, Weekly.test)
Direction.test <- Weekly.test$Direction
conf.mat.4 <- table(qda.pred$class, Direction.test)
conf.mat.4
accuracy.qda <- mean(qda.pred$class == Direction.test)
misclassification_rate.qda <- 1 - accuracy.qda
accuracy.qda #= 0.5560
misclassification_rate.qda #0.4439
##This QDA model does not increase the accuracy. In fact, it decreases it by a small amount. This again points to Lag2 not having enough 
#significane for the test to differentiate the correct category for the response variable. Especially for this test. It predicted only 
#"Up" classifications. 


#### 7 ####
#All three of these models, Logistic, LDA, and QDA, come out with very similar predictions and misclassifications rates. All of them being approximately 56% accurate and 44% wrong. 
#This is barely better than flipping a coin to choose a category. There confusion matrices, though slightly different, hold pretty much the same amoun of miscalssified information. 
#The Logistic Regression Model is the best of the 3 though the difference is practically negligible. 
#Overall, I would say that this model model, nor any of the others in this report, can accurately predict the response variable direction. 
    \end{lstlisting}


\end{document}
