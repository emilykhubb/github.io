%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Short Sectioned Assignment
% LaTeX Template
% Version 1.0 (5/5/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Frits Wenneker (http://www.howtotex.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[paper=a4, fontsize=11pt]{scrartcl} % A4 paper and 11pt font size

\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{float}
\usepackage{graphicx}
\usepackage{listings}
    \lstset{language=R}
\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
\usepackage{fourier} % Use the Adobe Utopia font for the document - comment this line to return to the LaTeX default
\usepackage[english]{babel} % English language/hyphenation
\usepackage{amsmath,amsfonts,amsthm,amssymb} % Math packages
\usepackage{graphicx}
\usepackage{url}
\usepackage{tabto}

\usepackage{lipsum} % Used for inserting dummy 'Lorem ipsum' text into the template

\usepackage{sectsty} % Allows customizing section commands
\allsectionsfont{\centering \normalfont\scshape} % Make all sections centered, the default font and small caps

\usepackage{fancyhdr} % Custom headers and footers
\pagestyle{fancyplain} % Makes all pages in the document conform to the custom headers and footers
\fancyhead{} % No page header - if you want one, create it in the same way as the footers below
\fancyfoot[L]{} % Empty left footer
\fancyfoot[C]{} % Empty center footer
\fancyfoot[R]{\thepage} % Page numbering for right footer
\renewcommand{\headrulewidth}{0pt} % Remove header underlines
\renewcommand{\footrulewidth}{0pt} % Remove footer underlines
\setlength{\headheight}{13.6pt} % Customize the height of the header
\numberwithin{equation}{section} % Number equations within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{figure}{section} % Number figures within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{table}{section} % Number tables within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)

\setlength\parindent{0pt} % Removes all indentation from paragraphs - comment this line for an assignment with lots of text

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\newcommand{\horrule}[1]{\rule{\linewidth}{#1}} % Create horizontal rule command with 1 argument of height
\newcommand{\argmax}{\arg\!\max}
\title{	
\normalfont \normalsize 
\textsc{Mississippi State University} \\ [25pt] % Your university, school and/or department name(s)
\horrule{0.5pt} \\[0.4cm] % Thin top horizontal rule
\huge Data Analysis One  \\ % The assignment title
\horrule{2pt} \\[0.5cm] % Thick bottom horizontal rule
}

\author{Emily Hubbard} % Your name

\date{\normalsize\today} % Today's date or a custom date

\begin{document}

\maketitle % Print the title

%----------------------------------------------------------------------------------------
%	PROBLEM 1
%----------------------------------------------------------------------------------------

\section*{HW 1}
%\lipsum[2] % Dummy text

\textbf{SECTION ONE}\\

\textbf{Executive Summary:}\\

\textbf{A. Introduction:}

\qquad Understanding the factors that drive consumer brand choice is essential in predicting market behavior. Questions such as: Do discounts on a particular brand increase the likelihood of purchase? Does brand loyalty outweigh price sensitivity? How does a change in list price influence a customer’s final decision? These are the kinds of questions we will find answers to using the methods utilized in this report Analyzing the OJ data within R, we will find the factors that most influence a customer’s choice between Minute Maid (MM) and Citrus Hill (CH) orange juice brands. We will do so by fitting the data to both Ridge Regression Models(RRM) and Lasso Regression Models(LRM).\\ 

\textbf{B. Data Collection}

\begin{itemize}
\item \textbf{"Purchase"} A factor with levels CH and MM indicating whether the customer purchased Citrus Hill or Minute Maid Orange Juice. 
\item \textbf{"WeekofPurchase"} Week of Purchase
\item \textbf{"StoreID"} Store ID
\item \textbf{"PriceCH"} Price charged for CH
\item \textbf{"PriceMM"} Price charged for MM
\item \textbf{"DiscCH"} Discount offered for CH
\item \textbf{"DiscMM"} Discount offered for MM
\item \textbf{"SpecialCH"} Indicator of special on CH
\item \textbf{"SpecialMM"} Indicator of special on MM
\item \textbf{"LoyalCH"} Customer brand loyalty for CH
\item \textbf{"SalePriceMM"} Sale price for MM
\item \textbf{"SalePriceCH"} Sale price for CH
\item \textbf{"PriceDiff"} Sale price of MM less sale price of CH
\item \textbf{"Store7"} A factor with levels No and Yes indicating whether the sale is at Store 7.
\item \textbf{"PctDiscMM"} Percentage discount for MM
\item \textbf{"PctDiscCH"} Percentage discount for CH
\item \textbf{"ListPriceDiff"} List price of MM less list price of CH
\item \textbf{"STORE"} Which of 5 possible stores the sale occured at
\end{itemize}


\textbf{C. Summary Information}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\linewidth]{1.2 Purchase Outcomes .pdf}
    \caption{Basic Summary of Leuk Data}
    \label{fig:enter-label}
\end{figure}

This figure visualizes the proportion of the response variables that fall in the "CM" category versus the "MM" category.

\textbf{Correlation Chart for OJ Numerical Data:}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\linewidth]{2. Correlation Chart.pdf}
    \caption{Correlation Chart}
    \label{fig:enter-label}
\end{figure}
\textbf{Observations:}

\qquad This plot provides a dizzying amount of information. The only valuable piece I want to point out is the myriad of high-correlation calculations. There are 15 that are greater than $\lvert0.5\rvert$ which indicates a very high multicollinearity across the various variables in the data set. Reducing multicollinearity is one of the many reasons to use ridge regression or lasso regression. \\

\textbf{D. Report Body}
\begin{enumerate}
    \item First, we will create a training set containing a random sample of 800 observations, and a test set containing the remaining observations. Then we will find the best lambda for a ridge regression model(RRM), fit the model, and interpret its coefficients. After that, we will calculate its Mean Squared Error(MSE) as well as produce a confusion matrix and misclassification rate to analyze the model's reliability and usefulness. \\

Before we get started, I want to define the response variable:

\[
Y = 
\begin{cases}
0 & \text{if Citrus Hill is purchased}\\
1 & \text{if Minute Maid is purchased}\\
\end{cases}
\]\\

Now that we have defined the response variable, we can use cross-validation to find the best lambda for our RRM. The following figure shows the lambda value at various levels of binomial deviance.

\textbf{Cross-Validation Curve:}\\ 
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{3. Cross-Validation Curve for Ridge Regression.pdf}
    \caption{R Summary Output}
    \label{fig:enter-label}
\end{figure} 
\textbf{Explanation:}\\
Notice that lowest point is the best lambda value because it allows for the lowest binomial deviation. This is the number that we will use in our RRM.
\begin{align}
\nonumber
&\lambda =0.031\\
\nonumber
-\text{Log}&(0.031) = 3.473\\
\nonumber
\text{(The -Log is added } & \text{for ease of Figure 0.3 interpretation)}
\end{align}

After calculating the best $\lambda$ value, it is now appropriate to fit the RRM to our data. The model produced the following coefficients: \\

\textbf{Ridge Regression Coefficients:}\\ 
\begin{figure}[H]
    \centering
    \includegraphics[width=0.25\linewidth]{4. Ridge Regression Coefficients .png}
    \caption{Ridge Regression Coefficients}
    \label{fig:enter-label}
\end{figure} 

\textbf{Observations:}

\qquad Because we are using the ridge regression method instead of lasso, the covariates deemed less influential compared to the others have values that near zero. In a lasso method, these values would simply be taken out. For this model, the corresponding covariate to any coefficient close to zero can be interpreted to be non-influential in predicting the response variable.

\qquad This leaves us to analyze the larger numbers more closely to figure out which are the most influential. The following are the top 5 most significant influencers:

\begin{align}
\nonumber
&\text{LoyalCH} = -4.362\\
\nonumber
&\text{PctDiscCH} = -1.687\\
\nonumber
&\text{DiscCH} = -0.951\\
\nonumber
&\text{ListPriceDiff} = -0.902\\
\nonumber
&\text{SalePriceCH} = +0.963\\
\nonumber
\end{align}

\qquad By far, the customer brand loyalty for CH is the greatest influence on the response variable. We can interpret this to mean that if a person has a brand loyalty to CH, the log-odds of a Minute Maid(MM) purchase fall 4.362 times per one unit increase in brand loyalty (though I am not sure how this qualitative covariate is measured). This coefficient makes perfect sense because a person loyal to Citrus Hill(CH) will have a lower probability to purchase MM. The same can be said of the next three covariates. The 5th covariate, unlike the rest, makes a positive impact on the probability of a MM purchase. It makes sense that an increase to the price of CH would constitute a larger probability of a MM purchase.

\qquad So, now that we have fit our model and understand the influence of individual covariates, it is now time to check the accuracy. Is this a reliable model? Will it be able to accurately predict whether or not MM will be purchased?\\

To answer these questions, we will do two things:
\begin{enumerate}[1.]
    \item Calculate the MSE.
    \item Produce a confusion matrix and subsequent accuracy and misclassification rates.\\
\end{enumerate}


\textbf{1. Calculating MSE:}
\begin{align}
\nonumber
&\text{MSE} = \frac{(\text{Actual}-\text{Predicted})^2}{\text{number of observations}}\\
\nonumber
&\text{MSE} = 0.132
\nonumber
\end{align}

This value really comes in handy when comparing the model to other methods and their corresponding MSE's.\\

\textbf{2. Producing Confusion Matrix and Rates:}

\qquad Using the remaining observations that were not used to train the model, we will ask the RRM to predict the values of those observations and then compare that with its actual value. This will produce the information we need to build a confusion matrix and calculate relevant rates.

The following is the confusion matrix and rates for our current RRM.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.50\linewidth]{Ridge Regression Confusion Matrix.png}
    \caption{Confusion Matrix}
    \label{fig:enter-label}
\end{figure} 

\textbf{Explanation:}
Overall, this model does a fair job at predicting the response variable with an accuracy rate of approximately 82.6 percent. The confusion matrix allows us to see which way the model is incorrectly guessing. For example, of the misclassifications, it is more likely to wrongly predict a purchase of CH when the actual purchase was MM ($\frac{34}{47}$ -- the proportion of CH predictions over total misclassifications). \\


\textbf{Summary of the RRM:}
\begin{enumerate}[1.]
    \item It keeps all 17 covariates.
    \item It has an MSE of 0.132.
    \item It has a fairly high accuracy rate.
    \item It is more likely to wrongly predict a CH purchase.\\
\end{enumerate}








































    \item Now, we will repeat this process for a different model -- Lasso Regression Model(LRM). (Note: the response variable remains the same.)\\

As we did with the RRM, we can use cross-validation to find the best lambda for LRM. The following figure shows the lambda value at various levels of binomial deviance.

\textbf{Cross-Validation Curve:}\\ 
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{5. Cross-Validation Curve for Lasso Regression.pdf}
    \caption{R Summary Output}
    \label{fig:enter-label}
\end{figure} 
\textbf{Explanation:}\\
As with the RRM, the lambda with the lowest binomial deviance becomes the best fit lambda for our model. As can be observed, this value falls around 4.7 which is the negative log value of lambda.

\begin{align}
\nonumber
&\lambda =0.009\\
\nonumber
-\text{Log}&(0.009) = 4.711\\
\nonumber
\text{(The -Log is added } & \text{for ease of Figure 0.6 interpretation)}
\end{align}

After calculating the best $\lambda$ value, it is now appropriate to fit the LRM to our data. The model produced the following coefficients: \\

\textbf{Lasso Regression Coefficients:}\\ 
\begin{figure}[H]
    \centering
    \includegraphics[width=0.25\linewidth]{6. Lasso Regression Coefficients.png}
    \caption{Lasso Regression Coefficients}
    \label{fig:enter-label}
\end{figure} 

\textbf{Observations:}

\qquad This model trims the covariates down to 7. It chose the most influential covariates, kept them, and got rid of the rest. This reduction in covariates helps immensely when it comes interpretation. It is more simple to draw conclusions from a smaller set of covariates.

\qquad This leaves us to analyze the larger numbers more closely to figure out which are the most influential. The following are the top 5 most significant influencers:

\begin{align}
\nonumber
&\text{LoyalCH} = -5.572\\
\nonumber
&\text{PctDiff} = -2.158\\
\nonumber
&\text{DiscCH} = -0.825\\
\nonumber
&\text{Store7Yes} = -0.521\\
\nonumber
&\text{SalePriceCH} = +0.225
\nonumber
\end{align}

\qquad My immediate observation is how different these covariates are from the RRM covariates. Loyalty to CH remains the same, but the majority of the covariates have shifted. However, this is normal. Of the 17 covariates to beging with, 4 or 5 are derived from the same information. These lead to having similar influences on the prediction, so these correlations must be dealt with somehow. Both models deal with multicollinearity differently. RRM shrinks coefficients and balances out the duplicate emphsis. LRM simply chooses one and gets ride of the rest. With that being said, it makes sense that the covariates would be a little different.

\qquad As we did for the RRM, we will now check the accuracy of the model.\\

We will use the same methods to analyze reliability:
\begin{enumerate}[1.]
    \item Calculate the MSE.
    \item Produce a confusion matrix and subsequent accuracy and misclassification rates.\\
\end{enumerate}


\textbf{1. Calculating MSE:}
\begin{align}
\nonumber
&\text{MSE} = \frac{(\text{Actual}-\text{Predicted})^2}{\text{number of observations}}\\
\nonumber
&\text{MSE} = 0.126
\nonumber
\end{align}

When compared to the RRM MSE, it is smaller. The smaller the MSE, the better.\\

\textbf{2. Producing Confusion Matrix and Rates:}

\qquad Using the same process as before, we will use the leftover observations to test the model and produce the following information:

The following is the confusion matrix and rates for our current LRM.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.50\linewidth]{Lasso Regression Confusion Matrix.png}
    \caption{Confusion Matrix}
    \label{fig:enter-label}
\end{figure} 

\textbf{Explanation:}

\qquad Overall, this model does a slightly better job at predicting the response variable with an accuracy rate of approximately 83.3 percent, 0.7 percent more than the RRM. Similar to the RRM, the LRM is more likely to wrongly predict a purchase of CH when the actual purchase was MM ($\frac{33}{45}$ -- the proportion of CH predictions over total misclassifications).


\textbf{Summary of the LRM:}
\begin{enumerate}[1.]
    \item It keeps 7 covariates.
    \item It has an MSE of 0.126.
    \item It has a fairly high accuracy rate.
    \item It is more likely to wrongly predict a CH purchase.\\
\end{enumerate}

    \item Finally, we will compare our two models and decide which one is superior.\\

\textbf{Conclusion:}

\qquad The lasso model makes correct predictions 0.7 percent more times than the ridge model. Is this a huge difference? No, but in a much larger population, this percentage could make a significant impact. The lasso also has a slightly lower MSE (smaller by 0.006). This also indicates a superior model. Therefore, the lasso is the superior test according to the accuracy rate and MSE calculation.\\

Overall, which of these models is best? 

\qquad The lasso regression model is the superior choice. It achieves greater accuracy with a smaller MSE while also keeping fewer covariates. This indicates a simpler model maintaining high accuracy with greater ease of interpretability. 


\newpage

\textbf{SECTION TWO}\\

\textbf{Executive Summary:}\\

\textbf{A. Introduction:}

\qquad In this section of the report, we will be transforming a data set into its Principle Components and analyzing the output. These principle components are made up of all of the variables in varying proportions in an attempt to capture as much of the total variance in the data as possible using fewer dimensions.\\

\textbf{B. Data}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\linewidth]{Variable Type of USArrests Data Set.png}
    \caption{Variable Type of USArrests Data}
    \label{fig:enter-label}
\end{figure}

\begin{itemize}
\item \textbf{"Murder"} numeric	Murder arrests (per 100,000)
\item \textbf{"Assault"} numeric Assault arrests (per 100,000)
\item \textbf{"UrbanPop"} numeric Percent urban population
\item \textbf{"Rape"} numeric Rape arrests (per 100,000)\\
\end{itemize}

\textbf{C. Summary Information}

\qquad PCA is particularly useful for the USArrests dataset because the four variables— Murder, Assault, UrbanPop, and Rape —are likely correlated and may contain overlapping information. By applying PCA, we can reduce these correlated variables into a smaller number of uncorrelated components that capture most of the total variance.

\qquad In doing so, we shift our perspective from isolated variables to composite measures that reflect the most important sources of variation in the dataset. While this shift reduces the ability to interpret each variable individually, it allows for a more holistic view of the underlying structure.\\

\textbf{D. Report Body}
\begin{enumerate}
    \item We will perform PCA on the USArrests data set, which is part of the base ISLR package.\\

\textbf{Output and Summary of PCA:}\\ 
\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\linewidth]{9. Results and Summary of PCA.png}
    \caption{Results and Summary of PCA}
    \label{fig:enter-label}
\end{figure}   

\textbf{Interpretation of the Summary:}

\qquad This output gives us a wealth of information. First, take a look at the cumulative proportion on the last line. These values tell us that nearly 87 percent of the variance is taken into account with the first two principle components alone. For this reason, we will be using $PC_1$ and $PC_2$ to make our interpretations and conclusions. 

\qquad Now that we have decided that, we can take a closer look at $PC_1$ and $PC_2$. Below, are the weighted sums of $PC_1$ and $PC_2$. This indicates the proportion of information that is provided by the corresponding covariate when calculating the principle component, also known as "loadings". \\

\textbf{Principle Components Weighted Sums:}
\begin{align}
\nonumber
&\text{PC}_1 = -0.536(\text{Murder}) -0.583(\text{Assault}) -0.278(\text{UrbanPop}) -0.543(\text{Rape})\\
\nonumber
&\text{PC}_2 = -0.418(\text{Murder}) -0.188(\text{Assault}) +0.872(\text{UrbanPop}) +0.167(\text{Rape})
\nonumber
\end{align} 

Why do these weighted sums matter? What can they tell us about crime rates in the 50 US states?

\qquad They tell us a lot actually. $PC_1$ has coefficients that have similar weights. This means that this component takes those 3 variables into pretty equal account. It has a smaller urban pop coefficient which simply means it doesn't focus on the effect of urbanization as much as, say, another principle component like $PC_2$. With equal weightings on the crimes and a smaller emphasis on urban population, this PC would be a good indicator for overall crime rates.

\qquad On the other hand, $PC_2$ puts a large emphasis on urban population making it a good indicator for the effect of urbanization on the crime rate. This principle component gives us a more detailed look at which crimes are more common in states with low or high urbanization.

\qquad Findings like these help us make connections between covariates that we likely never would have seen with a simpler model.\\

\textbf{Visualization of PCA:} 
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{10. Principle Component Analysis Visual.pdf}
    \caption{Principle Component Analysis Visual}
    \label{fig:enter-label}
\end{figure}   



\textbf{Interpretation of the Visual:}

\qquad Let's start by looking at the arrows. The direction of the arrows tells us whether that variable has a positive or negative load on the component. For example, all 4 variables point left reletive to the x-axis which corresponds to the fact that all of those loads are negative for $PC_1$. Similarly, if the plot were viewed 90° clockwise, the relative directions of the arrows would align with the loadings on $PC_2$. The length of the arrows explains the magnitude of the effect on the component. For ease of explanation, we will primarily focus on $PC_1$. All three crimes have similar lengths which supports the similar coefficients found in the weighted sum of $PC_1$. States that fall in the direction of the arrows indicate a higher number for those variables. This means that states farther left have higher crime rates because that is the direction that murder, rape, and assault point. Similarly, you could say that states on the right have lower crime rates. \\

\textbf{Overall Conclusions:}

\qquad This PCA transformation works really well for this data set. It gives us unique information that would not have been captured in other methods or models. Do we lose interpretibiliy of individual variables? Yes. However, in a sense, we are gaining a new set of interpretations that have their own inherent value.


\end{enumerate}

\newpage

\textbf{\underline{APPENDIX}}\\
\textbf{R code:}\\

    \begin{lstlisting}[language=R]
#### HW 4 ####
#### 1 ####
library(ISLR)
data(OJ)
View(OJ)
?OJ
summary(OJ)
str(OJ)

### Visuals of Data
library(ggplot2)

ggplot(OJ, aes(x = Purchase, fill = Purchase)) +
  geom_bar() +
  labs(title = "Distribution of Purchase Types")

### Numerical Data
num_vars <- OJ[, sapply(OJ, is.numeric)]

library(PerformanceAnalytics)
chart.Correlation(num_vars,method="spearman",histogram=TRUE,pch=16, main = "Correlation Chart")

#### a ####
set.seed (1)
sample.index = sample (1:nrow(OJ), 800)
train <- OJ[sample.index,]
test <- OJ[-sample.index, ]

#### b ####
### Ridge Regression
library (glmnet )

#Split Data intor Train and Test Data
x_train <- model.matrix(Purchase ~ ., data = train)[, -1]
y_train <- train$Purchase

x_test  <- model.matrix(Purchase ~ ., data = test)[, -1]
y_test  <- test$Purchase

#Determine Best Lambda Using Cross-Validation
cv_ridge <- cv.glmnet(x_train, y_train, alpha = 0, family = "binomial")
plot(cv_ridge, main = "Cross-Validation Curve for Ridge Regression")

#Best Lambda
cv_ridge$lambda.min
# =0.031

#Ridge Regression Given Best Lambda
ridge_mod <- glmnet(x_train, y_train, alpha = 0, family = "binomial", lambda = cv_ridge$lambda.min)
ridge_mod

ridge_probs <- predict(ridge_mod, s = cv_ridge$lambda.min, newx = x_test, type = "response")
ridge_probs
ridge_pred <- ifelse(ridge_probs > 0.5, "MM", "CH")
ridge_pred <- factor(ridge_pred, levels = levels(y_test))

conf.mat.ridge <- table(ridge_pred, y_test)
accuracy.ridge <- mean(ridge_pred == y_test)
misclassification.rate.ridge <- 1 - accuracy.ridge

print(conf.mat.ridge)
print(accuracy.ridge)
print(misclassification.rate.ridge)

#### c ####
coef(ridge_mod)

#### d ####
y_test_num <- ifelse(y_test == "MM", 1, 0) 
#turning the factors into binary outcomes so that it can 
#the predicted probabilities can be subtracted and a mean residual error can be found.
ridge_mse <- mean((y_test_num - ridge_probs)^2)
ridge_mse
#=0.132

#### e ####
### Lasso Regression
#Determine Best Lambda Using Cross-Validation
cv_lasso <- cv.glmnet(x_train, y_train, alpha = 1, family = "binomial")
plot(cv_lasso, main = "Cross-Validation Curve for Lasso Regression")

#Best Lambda
cv_lasso$lambda.min
#=0.009

#Ridge Regression Given Best Lambda
lasso_mod <- glmnet(x_train, y_train, alpha = 1, family = "binomial", lambda = cv_lasso$lambda.min)
lasso_mod

coef(lasso_mod)

lasso_probs <- predict(lasso_mod, s = cv_lasso$lambda.min, newx = x_test, type = "response")
lasso_probs
lasso_pred <- ifelse(lasso_probs > 0.5, "MM", "CH")
lasso_pred <- factor(lasso_pred, levels = levels(y_test))

conf.mat.lasso <- table(lasso_pred, y_test)
accuracy.lasso <- mean(lasso_pred == y_test)
misclassification.rate.lasso <- 1 - accuracy.lasso

print(conf.mat.lasso)
print(accuracy.lasso)
print(misclassification.rate.lasso)

lasso_mse <- mean((y_test_num - lasso_probs)^2)
lasso_mse
#=0.126

#### f ####
cv_lasso$lambda.min
#=0.009

#### g ####
accuracy.diff.pct <- (accuracy.lasso - accuracy.ridge)*100
accuracy.diff.pct
#0.74% This means the lasso model makes correct predictions 0.74% more times than the ridge model.
#Is it a huge difference? No, but in a much larger population, this percentage could make a significant impact.
#Therefore, the lasso is the superior test according to the accuracy estimate alone.

#The lasso also has a slightly lower MSE (smaller by 0.006). This also indicates a superior model.

#### h ####
#Overall, which of these models is best? The lasso regression model achieves greater accuracy with a smaller MSE while also 
#keeping a smaller number of covariates. This indicates a simpler model with greater ease of interpretability. 




#### 2 ####
data(USArrests)
View(USArrests)
?USArrests
summary(USArrests)
str(USArrests)

library (pls)
?pcr
?prcomp

#Splitting Data into Principle Components
pca.fit <- prcomp(USArrests, scale. = TRUE)
pca.fit
summary(pca.fit)

#Visual for PCA
biplot(pca.fit, scale=0, main = "Principle Component Analysis Visual")
 
    \end{lstlisting}


\end{document}
